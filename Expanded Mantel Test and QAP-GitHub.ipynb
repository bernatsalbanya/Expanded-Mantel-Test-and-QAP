{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc40b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import mantel\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from scipy.stats import t, pearsonr\n",
    "from sklearn.utils import shuffle\n",
    "import igraph\n",
    "from igraph import Graph, GraphBase\n",
    "from itertools import permutations\n",
    "from scipy import spatial, stats\n",
    "from scipy.optimize import quadratic_assignment\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "import scipy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import seaborn as sns\n",
    "import random\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb6817",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions\n",
    "def triangles(g):\n",
    "    cliques = GraphBase.cliques(g,min=3, max=3)\n",
    "    result = [0] * GraphBase.vcount(g)\n",
    "    for i, j, k in cliques:\n",
    "        result[i] += 1\n",
    "        result[j] += 1\n",
    "        result[k] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c60a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_none_to_one(matrix):\n",
    "    \"\"\" Convert None values in the matrix to 1 \"\"\"\n",
    "    # Convert the matrix to a numpy array with object dtype to handle None\n",
    "    matrix = np.array(matrix, dtype=object)\n",
    "    # Replace None with 1\n",
    "    matrix[matrix == None] = 1\n",
    "    # Convert the matrix to float\n",
    "    return matrix.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intervals(start, end, step):\n",
    "    intervals = []\n",
    "    \n",
    "    current = start\n",
    "    while current <= end:\n",
    "        if current + step - 1 <= end:\n",
    "            intervals.append((current, current + step - 1))\n",
    "            current += step\n",
    "        else:\n",
    "            intervals.append((end - step + 1, end))\n",
    "            current += step\n",
    "\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49103957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(network, permuted_B, permuted_idx):\n",
    "    metrics = {\n",
    "        'edges_betweenness': np.nanmean(network.edge_betweenness(weights='weight')),\n",
    "        'betweenness': np.nanmean(network.betweenness(weights='weight')),\n",
    "        'closeness': np.nanmean(network.closeness(weights='weight')),\n",
    "        'assortativity': network.assortativity_degree(),\n",
    "        'triangles_num': len(network.list_triangles()),\n",
    "        'triangles_avg': np.nanmean(triangles(network)),\n",
    "        'local_clustering': network.transitivity_avglocal_undirected(),\n",
    "        'global_clustering': network.transitivity_undirected(),\n",
    "        'avg_path_len': network.average_path_length(),\n",
    "        'all_strength': np.nanmean(network.strength(mode='all', weights='weight')),\n",
    "        'in_strength': np.nanmean(network.strength(mode='in', weights='weight')),\n",
    "        'out_strength': np.nanmean(network.strength(mode='out', weights='weight')),\n",
    "        'null_dist': np.corrcoef(permuted_B.flatten(), permuted_B[permuted_idx].flatten())[0, 1]\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e945b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewire_keeping_degseq(graph, niter, direc):\n",
    "    graph = graph.copy()  # Create a copy to avoid modifying the original graph\n",
    "\n",
    "    # Implement your rewiring logic here\n",
    "    for _ in range(niter):\n",
    "        id1, id2 = random.sample(list(np.arange(0,graph.ecount())), 2)\n",
    "        edge1 = graph.get_edgelist()[id1]\n",
    "        edge2 = graph.get_edgelist()[id2]\n",
    "\n",
    "        # Check if the new edges already exist\n",
    "        new_edge1 = (edge1[0], edge2[1])\n",
    "        new_edge2 = (edge2[0], edge1[1])\n",
    "        if not graph.are_connected(*new_edge1) and not graph.are_connected(*new_edge2):\n",
    "            # Preserve the weight of the original edges\n",
    "            weight1 = graph.es[id1][\"weight\"] if \"weight\" in graph.es.attributes() else 1.0\n",
    "            weight2 = graph.es[id2][\"weight\"] if \"weight\" in graph.es.attributes() else 1.0\n",
    "\n",
    "            # If the new edges don't exist, delete old edges and add new ones with preserved weights\n",
    "            graph.delete_edges([id1, id2])\n",
    "            graph.add_edges([new_edge1, new_edge2])\n",
    "            new_id1 = graph.get_eid(edge1[0], edge2[1], directed=direc)\n",
    "            new_id2 = graph.get_eid(edge2[0], edge1[1], directed=direc)\n",
    "            graph.es[new_id1][\"weight\"] = weight1 if weight1 is not None else 1.0\n",
    "            graph.es[new_id2][\"weight\"] = weight2 if weight2 is not None else 1.0\n",
    "                        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514bf5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlled_keeping_degseq(graph, list_edges, niter, direc):\n",
    "    graph = graph.copy()  # Create a copy to avoid modifying the original graph\n",
    "\n",
    "    # Implement your rewiring logic here\n",
    "    for _ in range(niter):\n",
    "        id1, id2 = random.sample(list_edges, 2)\n",
    "        edge1 = graph.get_edgelist()[id1]\n",
    "        edge2 = graph.get_edgelist()[id2]\n",
    "\n",
    "        # Check if the new edges already exist\n",
    "        new_edge1 = (edge1[0], edge2[1])\n",
    "        new_edge2 = (edge2[0], edge1[1])\n",
    "        if not graph.are_connected(*new_edge1) and not graph.are_connected(*new_edge2):\n",
    "            # Preserve the weight of the original edges\n",
    "            weight1 = graph.es[id1][\"weight\"] if \"weight\" in graph.es.attributes() else 1.0\n",
    "            weight2 = graph.es[id2][\"weight\"] if \"weight\" in graph.es.attributes() else 1.0\n",
    "\n",
    "            # If the new edges don't exist, delete old edges and add new ones with preserved weights\n",
    "            graph.delete_edges([id1, id2])\n",
    "            graph.add_edges([new_edge1, new_edge2])\n",
    "            new_id1 = graph.get_eid(edge1[0], edge2[1], directed=direc)\n",
    "            new_id2 = graph.get_eid(edge2[0], edge1[1], directed=direc)\n",
    "            graph.es[new_id1][\"weight\"] = weight1 if weight1 is not None else 1.0\n",
    "            graph.es[new_id2][\"weight\"] = weight2 if weight2 is not None else 1.0\n",
    "            \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bf2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rewiring_one_simulation(network, name_network, sim, bins):\n",
    "    \n",
    "    network_copy = network.copy()  # Create a copy of the network\n",
    "    \n",
    "    # Calculate the observed correlation coefficient\n",
    "    network_adj = np.array(network.get_adjacency(attribute='weight').data)\n",
    "    \n",
    "    # Convert None to 1 in network_adj\n",
    "    network_adj = convert_none_to_one(network_adj)\n",
    "    \n",
    "    permuted_idx = quadratic_assignment(network_adj, network_adj, options={'maximize': True})['col_ind']\n",
    "    observed_corr_coef = np.corrcoef(network_adj.flatten(), network_adj[np.arange(network_adj.shape[0])].flatten())[0, 1]\n",
    "\n",
    "    direction = network.is_directed()\n",
    "    iterations = round(network.ecount()/2)+1\n",
    "\n",
    "    # Initialize arrays with zeros\n",
    "    metrics = {metric: np.zeros((iterations)) for metric in metric_names}\n",
    "    p_values_cont = np.ones((iterations))\n",
    "\n",
    "    # Initialize initial metric values\n",
    "    original_betweenness = network.edge_betweenness(weights='weight')\n",
    "    initial_metrics = calculate_metrics(network, network_adj, permuted_idx)\n",
    "\n",
    "    # Populate initial metric values\n",
    "    for metric in metric_names:\n",
    "        initial_value = initial_metrics[metric]\n",
    "        metrics[metric][0] = initial_value\n",
    "\n",
    "    count = 0 \n",
    "    for it in range(0, iterations, 1):\n",
    "\n",
    "        # Create a graph with weighted edges\n",
    "        network_copy = rewire_keeping_degseq(network_copy, niter = it, direc = direction)\n",
    "\n",
    "        # Calculate metrics for the current iteration and simulation\n",
    "        permuted_B = np.array(network_copy.get_adjacency(attribute='weight').data)\n",
    "        \n",
    "        # Convert None to 1 in permuted_B\n",
    "        permuted_B = convert_none_to_one(permuted_B)\n",
    "        \n",
    "        permuted_idx = quadratic_assignment(network_adj, permuted_B, options={'maximize': True})['col_ind']\n",
    "        metrics_dict = calculate_metrics(network_copy, permuted_B, permuted_idx)\n",
    "\n",
    "        # Update the metrics dictionary\n",
    "        for metric, value in metrics_dict.items():\n",
    "            metrics[metric][count] = value\n",
    "\n",
    "        p_values_cont[count] = np.sum(np.abs(metrics['null_dist'][0:count+1]) >= np.abs(metrics['null_dist'][0])) / (count+1)\n",
    "\n",
    "        if count < iterations+1:\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    metrics_df = pd.DataFrame({f'{metric}': metrics[metric] for metric in metric_names})\n",
    "    p_values_df = pd.DataFrame({f'p_values': p_values_cont})\n",
    "\n",
    "    metrics_df.to_csv(\"../data/qap/stats_\"+str(name_network)+\"_rand_rew_metrics_\"+str(bins)+\"_bins_\"+str(sim)+\"_sim.csv\")\n",
    "    p_values_df.to_csv(\"../data/qap/stats_\"+str(name_network)+\"_rand_rew_p_values_\"+str(bins)+\"_bins_\"+str(sim)+\"_sim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cdaa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rewiring_parallel(network, simulations, name_network, bins):  \n",
    "    \n",
    "    Parallel(n_jobs=100)(delayed(random_rewiring_one_simulation)(network, name_network, sim, bins) for sim in range(simulations))\n",
    "\n",
    "    sim = 0\n",
    "    metrics_list = []  # List to store metrics DataFrames across simulations\n",
    "    p_values_list = []  # List to store p-values DataFrames across simulations    \n",
    "\n",
    "    while sim < simulations:\n",
    "        # Read the saved files for each simulation\n",
    "        metrics_df = pd.read_csv(\"../data/qap/stats_\"+str(name_network)+\"_rand_rew_metrics_\"+str(bins)+\"_bins_\"+str(sim)+\"_sim.csv\")\n",
    "        metrics_df.rename(columns={'Unnamed: 0': 'rewirings'}, inplace = True)\n",
    "        p_values_df = pd.read_csv(\"../data/qap/stats_\"+str(name_network)+\"_rand_rew_p_values_\"+str(bins)+\"_bins_\"+str(sim)+\"_sim.csv\")\n",
    "        p_values_df.rename(columns={'Unnamed: 0': 'rewirings'}, inplace = True)\n",
    "        \n",
    "        metrics_list.append(metrics_df)\n",
    "        p_values_list.append(p_values_df)\n",
    "\n",
    "        sim += 1\n",
    "\n",
    "    # Concatenate results across simulations\n",
    "    ensembled_metrics_df = pd.concat(metrics_list, keys=range(simulations), names=['simulation'])\n",
    "    ensembled_p_values_df = pd.concat(p_values_list, keys=range(simulations), names=['simulation'])\n",
    "           \n",
    "    # Compute mean and standard deviation across metrics DataFrames\n",
    "    metrics_mean_df = ensembled_metrics_df.groupby('rewirings').mean()\n",
    "    metrics_mean_df = metrics_mean_df.rename(columns=lambda x: x + '_mean')\n",
    "    metrics_std_df = ensembled_metrics_df.groupby('rewirings').std()\n",
    "    metrics_std_df = metrics_std_df.rename(columns=lambda x: x + '_std')\n",
    "    p_values_mean_df = ensembled_p_values_df.groupby('rewirings').mean()\n",
    "    p_values_mean_df = p_values_mean_df.rename(columns=lambda x: x + '_mean')\n",
    "    p_values_std_df = ensembled_p_values_df.groupby('rewirings').std()\n",
    "    p_values_std_df = p_values_std_df.rename(columns=lambda x: x + '_std')\n",
    "    \n",
    "    metrics_df_final = pd.concat([metrics_mean_df, metrics_std_df], axis=1)\n",
    "    p_values_df_final = pd.concat([p_values_mean_df, p_values_std_df], axis=1)\n",
    "\n",
    "    # Save mean and standard deviation DataFrames\n",
    "    metrics_df_final.to_csv(\"../data/qap/stats_\"+str(name_network)+\"_rand_rew_metrics_\"+str(bins)+\"_bins.csv\")\n",
    "    p_values_df_final.to_csv(\"../data/qap/stats_\"+str(name_network)+\"_rand_rew_p_values_\"+str(bins)+\"_bins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7101a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlled_rewiring_one_simulation(network, name_network, bins, sim):\n",
    "    \n",
    "    # Calculate the observed correlation coefficient\n",
    "    network_adj = np.array(network.get_adjacency(attribute='weight').data)\n",
    "    permuted_idx = quadratic_assignment(network_adj, network_adj, options={'maximize': True})['col_ind']\n",
    "    observed_corr_coef = np.corrcoef(network_adj.flatten(), network_adj[np.arange(network_adj.shape[0])].flatten())[0, 1]\n",
    "\n",
    "    direction = network.is_directed()\n",
    "\n",
    "    #Create the size of the groups of edges\n",
    "    if round(network.ecount()*bins)/2 == 0: \n",
    "        e_groups = math.floor(network.ecount()*bins)\n",
    "    else:\n",
    "        e_groups = math.floor(network.ecount()*bins)+1\n",
    "    if e_groups == 0: \n",
    "        e_groups = 4\n",
    "        bins = e_groups/network.ecount()\n",
    "    if e_groups > math.floor(network.ecount()/2) and (bins < 1): #Fit the bins either <0.5 or =1\n",
    "        e_groups = math.floor((network.ecount()-1)/2)\n",
    "        bins = round(e_groups/(network.ecount()-1),2)\n",
    "    intervals = generate_intervals(0, network.ecount()-1, e_groups) #Generate the intervals \n",
    "    iterations = round(len(intervals)*e_groups/2)+1\n",
    "      \n",
    "    # Initialize arrays with zeros\n",
    "    metrics = {metric: np.zeros((iterations+1)) for metric in metric_names}\n",
    "    p_values_cont = np.ones((iterations+1))\n",
    "\n",
    "    # Initialize initial metric values\n",
    "    original_betweenness = network.edge_betweenness(weights='weight')\n",
    "    initial_metrics = calculate_metrics(network, network_adj, permuted_idx)\n",
    "    \n",
    "    # Populate initial metric values\n",
    "    for metric in metric_names:\n",
    "        initial_value = initial_metrics[metric]\n",
    "        metrics[metric][0] = initial_value\n",
    "\n",
    "    count = 0 \n",
    "    network_copy = network.copy()  # Create a copy of the network\n",
    "\n",
    "    edge_tuples = network.get_edgelist() # Get the edge of the network\n",
    "    edges = [list(edge) for edge in edge_tuples] # Convert the tuple into list\n",
    "    edges = [(index, item) for index, item in enumerate(edges)]\n",
    "    control_metric = network.edge_betweenness(weights = network.es['weight']) # Calculate edge betweenness\n",
    "\n",
    "    combined_lists = list(zip(edges, control_metric)) # Zip the two lists together\n",
    "    sorted_combined_lists = sorted(combined_lists, key=lambda x: x[1]) # Sort based on the values control_metric    \n",
    "    sorted_edges, sorted_control_metric = zip(*sorted_combined_lists) # Unzip the sorted list\n",
    "    sorted_ids, sorted_edges = zip(*sorted_edges) # Unzip the sorted list\n",
    "    sorted_ids = list(sorted_ids) # Convert the tuple into list   \n",
    "\n",
    "    for interval in intervals:\n",
    "        init, end = interval[0], interval[1]+1\n",
    "        edges_int = list(np.arange(init, end))\n",
    "        suff_edges_int = sorted_ids[init:end].copy()\n",
    "\n",
    "        for it in range(0, round(len(suff_edges_int)/2), 1):\n",
    "\n",
    "            # Create a graph with weighted edges\n",
    "            network_copy = controlled_keeping_degseq(network_copy, suff_edges_int, niter = it, direc = direction)\n",
    "\n",
    "            # Calculate metrics for the current iteration and simulation\n",
    "            permuted_B = np.array(network_copy.get_adjacency(attribute='weight').data)\n",
    "            permuted_idx = quadratic_assignment(network_adj, permuted_B, options={'maximize': True})['col_ind']\n",
    "            metrics_dict = calculate_metrics(network_copy, permuted_B, permuted_idx)\n",
    "\n",
    "            # Update the metrics dictionary\n",
    "            for metric, value in metrics_dict.items():\n",
    "                metrics[metric][count] = value\n",
    "\n",
    "            p_values_cont[count] = np.sum(np.abs(metrics['null_dist'][0:count+1]) >= np.abs(metrics['null_dist'][0])) / (count+1)\n",
    "\n",
    "            if count < iterations:\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "    metrics_df = pd.DataFrame({f'{metric}': metrics[metric] for metric in metric_names})\n",
    "    p_values_df = pd.DataFrame({f'p_values': p_values_cont})\n",
    "    \n",
    "    metrics_df.to_csv(\"../data/qap/stats_\"+str(name_network)+\"_cont_rew_metrics_\"+str(bins)+\"_bins_\"+str(sim)+\"_sim.csv\")\n",
    "    p_values_df.to_csv(\"../data/qap/stats_\"+str(name_network)+\"_cont_rew_p_values_\"+str(bins)+\"_bins_\"+str(sim)+\"_sim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e0b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlled_rewiring_parallel(network, simulations, name_network, bins):  \n",
    "    \n",
    "    Parallel(n_jobs=100)(delayed(controlled_rewiring_one_simulation)(network, name_network, bins, sim) for sim in range(simulations))\n",
    "\n",
    "    sim = 0\n",
    "    metrics_list = []  # List to store metrics DataFrames across simulations\n",
    "    p_values_list = []  # List to store p-values DataFrames across simulations    \n",
    "\n",
    "    while sim < simulations:\n",
    "        # Read the saved files for each simulation\n",
    "        metrics_df = pd.read_csv(\"../data/qap/stats_\"+str(name_network)+\"_cont_rew_metrics_\"+str(bins)+\"_bins_\"+str(sim)+\"_sim.csv\")\n",
    "        metrics_df.rename(columns={'Unnamed: 0': 'rewirings'}, inplace = True)\n",
    "        p_values_df = pd.read_csv(\"../data/qap/stats_\"+str(name_network)+\"_cont_rew_p_values_\"+str(bins)+\"_bins_\"+str(sim)+\"_sim.csv\")\n",
    "        p_values_df.rename(columns={'Unnamed: 0': 'rewirings'}, inplace = True)\n",
    "        \n",
    "        metrics_list.append(metrics_df)\n",
    "        p_values_list.append(p_values_df)\n",
    "\n",
    "        sim += 1 \n",
    "\n",
    "    # Concatenate results across simulations\n",
    "    ensembled_metrics_df = pd.concat(metrics_list, keys=range(simulations), names=['simulation'])\n",
    "    ensembled_p_values_df = pd.concat(p_values_list, keys=range(simulations), names=['simulation'])\n",
    "           \n",
    "    # Compute mean and standard deviation across metrics DataFrames\n",
    "    metrics_mean_df = ensembled_metrics_df.groupby('rewirings').mean()\n",
    "    metrics_mean_df = metrics_mean_df.rename(columns=lambda x: x + '_mean')\n",
    "    metrics_std_df = ensembled_metrics_df.groupby('rewirings').std()\n",
    "    metrics_std_df = metrics_std_df.rename(columns=lambda x: x + '_std')\n",
    "    p_values_mean_df = ensembled_p_values_df.groupby('rewirings').mean()\n",
    "    p_values_mean_df = p_values_mean_df.rename(columns=lambda x: x + '_mean')\n",
    "    p_values_std_df = ensembled_p_values_df.groupby('rewirings').std()\n",
    "    p_values_std_df = p_values_std_df.rename(columns=lambda x: x + '_std')\n",
    "    \n",
    "    metrics_df_final = pd.concat([metrics_mean_df, metrics_std_df], axis=1)\n",
    "    p_values_df_final = pd.concat([p_values_mean_df, p_values_std_df], axis=1)\n",
    "\n",
    "    # Save mean and standard deviation DataFrames\n",
    "    metrics_df_final.to_csv(\"../data/qap/stats_\"+str(name_network)+\"_cont_rew_metrics_\"+str(bins)+\"_bins.csv\")\n",
    "    p_values_df_final.to_csv(\"../data/qap/stats_\"+str(name_network)+\"_cont_rew_p_values_\"+str(bins)+\"_bins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d958c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(ax, cont_rew, rand_rew, metric_name, simulations):\n",
    "    x_max = min(len(cont_rew[\"rewirings\"].values), len(rand_rew[\"rewirings\"].values))\n",
    "    ax.x = np.arange(0,x_max)\n",
    "    ax.original = np.repeat(cont_rew[metric_name+\"_mean\"][0], len(ax.x))\n",
    "    ax.mean_cont = cont_rew[metric_name+\"_mean\"].values[0:len(ax.x)]\n",
    "    ax.std_cont = cont_rew[metric_name+\"_std\"].values[0:len(ax.x)]\n",
    "    ax.mean_rand = rand_rew[metric_name+\"_mean\"].values[0:len(ax.x)]\n",
    "    ax.std_rand = rand_rew[metric_name+\"_std\"].values[0:len(ax.x)]\n",
    "    ax.set(xlim=(0, x_max-1))\n",
    "    ax.plot(ax.x, ax.original, 'k-', label='Original')\n",
    "    ax.fill_between(ax.x, ax.original, ax.original, color='k', alpha=0.2)\n",
    "    ax.plot(ax.x, ax.mean_cont, '#ED7D31', label='Controlled Rewiring')\n",
    "    ax.fill_between(ax.x, ax.mean_cont - ax.std_cont, ax.mean_cont + ax.std_cont, color='#ED7D31', alpha=0.2)\n",
    "    ax.plot(ax.x, ax.mean_rand, color = '#4472C4', linestyle = '-', label='Random Rewiring')\n",
    "    ax.fill_between(ax.x, ax.mean_rand - ax.std_rand, ax.mean_rand + ax.std_rand, color='#4472C4', alpha=0.2)\n",
    "    ax.labs = [item.get_text() for item in ax.get_yticklabels()]\n",
    "    ax.yaxis.set_tick_params(labelsize=12)\n",
    "    ax.xaxis.set_tick_params(labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e5d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PanelPlot(name, simulations, bins):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 10), sharey=False)\n",
    "    sns.set()\n",
    "    sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "\n",
    "    for i, metric_name in enumerate(metric_names):\n",
    "        if i == len(metric_names) - 4:\n",
    "            break\n",
    "        else:\n",
    "            row, col = divmod(i, 3)\n",
    "            ax = axes[row, col]\n",
    "            cont_rew = pd.read_csv(f\"../data/qap/stats_{name_network}_cont_rew_metrics_{bins}_bins.csv\", sep=',')\n",
    "            cont_rew = cont_rew.rename(columns={'Unnamed: 0': 'rewirings'})\n",
    "            cont_rew = cont_rew.sort_values(by='rewirings')\n",
    "            cont_rew = cont_rew.reset_index(drop=True)\n",
    "            cont_rew = cont_rew[0:len(cont_rew['rewirings'])]\n",
    "            \n",
    "            rand_rew = pd.read_csv(f\"../data/qap/stats_{name_network}_rand_rew_metrics_{bins}_bins.csv\")\n",
    "            rand_rew = rand_rew.rename(columns={'Unnamed: 0': 'rewirings'})\n",
    "            rand_rew = rand_rew.sort_values(by='rewirings')\n",
    "            rand_rew = rand_rew.reset_index(drop=True)\n",
    "            rand_rew = rand_rew[0:len(rand_rew['rewirings'])]\n",
    "            plot_metric(ax, cont_rew, rand_rew, metric_name, simulations)\n",
    "\n",
    "            ax.set_title(f'Average {metric_name.capitalize().replace(\"_\", \" \")}', fontsize=12)\n",
    "            ax.set_xlabel('Number of rewirings', fontsize=12)\n",
    "            ax.set_ylabel('Metric Value', fontsize=12)\n",
    "\n",
    "    handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=4, fontsize=12)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    #plt.savefig(f\"../{name}_metrics.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d9721",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebf826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import networks\n",
    "karate = igraph.read(\"karate.gml\", format = \"edgelist\")\n",
    "karate.es['weight'] = 1\n",
    "karate.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f41742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose network and set number of simulations and rewirings\n",
    "network = karate.copy()\n",
    "name_network = 'karate_100sim'\n",
    "simulations = 100\n",
    "bins = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27852dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays\n",
    "metric_names = ['edges_betweenness', 'betweenness', 'closeness', 'assortativity',\n",
    "                'triangles_num', 'triangles_avg', 'local_clustering',\n",
    "                'global_clustering', 'avg_path_len', 'all_strength',\n",
    "                'in_strength', 'out_strength', 'null_dist']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9eef9",
   "metadata": {},
   "source": [
    "### Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlled_rewiring_parallel(network, simulations, name_network, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f071bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rewiring_parallel(network, simulations, name_network, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840505d",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a716f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming x_max is defined elsewhere\n",
    "PanelPlot(name_network, simulations, bins)  # Replace with the actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d83433",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "rand_p_values = pd.read_csv(f\"../data/qap/stats_{name_network}_rand_rew_p_values_{bins}_bins.csv\", sep=',')\n",
    "rand_p_values = rand_p_values.rename(columns={'Unnamed: 0': 'rewirings'})\n",
    "rand_p_values = rand_p_values.sort_values(by='rewirings')\n",
    "rand_p_values = rand_p_values.reset_index(drop=True)\n",
    "rand_p_values = rand_p_values[0:len(rand_p_values['rewirings'])]\n",
    "\n",
    "cont_p_values = pd.read_csv(f\"../data/qap/stats_{name_network}_cont_rew_p_values_{bins}_bins.csv\", sep=',')\n",
    "cont_p_values = cont_p_values.rename(columns={'Unnamed: 0': 'rewirings'})\n",
    "cont_p_values = cont_p_values.sort_values(by='rewirings')\n",
    "cont_p_values = cont_p_values.reset_index(drop=True)\n",
    "cont_p_values = cont_p_values[0:len(cont_p_values['rewirings'])]\n",
    "\n",
    "x_max = min(len(cont_p_values[\"rewirings\"].values), len(rand_p_values[\"rewirings\"].values))\n",
    "x = np.arange(0,x_max)\n",
    "\n",
    "original = np.repeat(1,len(x))/np.arange(1,len(x)+1)\n",
    "mean_cont = cont_p_values[\"p_values_mean\"].values[0:len(x)]\n",
    "std_cont = cont_p_values[\"p_values_std\"].values[0:len(x)]\n",
    "mean_rand = rand_p_values[\"p_values_mean\"].values[0:len(x)]\n",
    "std_rand = rand_p_values[\"p_values_std\"].values[0:len(x)]\n",
    "\n",
    "plt.plot(x, np.repeat(0.05,len(x)), 'r-', label='alpha = 0.05')\n",
    "plt.plot(x, original, 'k-', label='Permutation')\n",
    "#plt.fill(x, original, original, color='k', alpha=0.2)\n",
    "plt.plot(x, mean_cont, '#ED7D31', label='Controlled Rewiring')\n",
    "plt.fill_between(x, np.maximum(mean_cont - std_cont,0), np.minimum(mean_cont + std_cont,1), mean_cont + np.repeat(0.1,len(x)), color='#ED7D31', alpha=0.2)\n",
    "plt.plot(x, mean_rand, color = '#4472C4', linestyle = '-', label='Random Rewiring')\n",
    "plt.fill_between(x, np.maximum(mean_rand - std_rand, 0), np.minimum(mean_rand + std_rand,1), color='#4472C4', alpha=0.2)\n",
    "\n",
    "plt.xlabel('Number of rewirings', fontsize=12)\n",
    "plt.ylabel('p-value', fontsize=12)\n",
    "\n",
    "#handles, labels = plt.get_legend_handles_labels()\n",
    "lgd = plt.legend(loc='lower center', bbox_to_anchor=(0.5,-0.45), ncol=2, fontsize=12)\n",
    "\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "\n",
    "plt.savefig(\"../\"+name_network+\"_p_value_\"+str(bins)+\"_bins.pdf\", dpi = 300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b83b4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
